{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lg2hLK7hlWdb"
   },
   "source": [
    "# Classifying Fashion-MNIST\n",
    "\n",
    "이제 neural network을 만들고 훈련시킬 차례이다. MNIST dataset에 대해서 drop-in 대체로 [Fashion-MNIST dataset](https://github.com/zalandoresearch/fashion-mnist)를 사용할 예정이다. MNIST는 실제로 97% 정확도 이상을 쉽게 달성할 수 있다. Fashion-MNIST는 28x28 greyscale 옷 images의 집합이다. MNIST보다 더 복잡해서 network의 실제 성능과 실제 세상에서 사용하는 dataset의을 더잘 나타낸다.\n",
    "\n",
    "<img src='assets/fashion-mnist-sprite.png' width=500px>\n",
    "\n",
    "이 notebook에서는 여러분 자신의 neural network를 만들어보자. 대부분은 Part 3에서 그냥 복사 및 붙여넣기하면 된다. 코드를 스스로 작성해서 동작시키는 것이 중요하다. 이를 통해서 이전에 notebook을 참고해도 된다.\n",
    "\n",
    "먼저 리소스를 import하고 Fashion-MNIST dataset을 `tensorflow_datasets`에서 다운받자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EMflYTIOtOPf"
   },
   "source": [
    "## Import Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U0n2QWj1p2fG"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "tfds.disable_progress_bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = tf.get_logger()\n",
    "logger.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "FwP1_Qw-cCsY",
    "outputId": "5cc63000-690c-4063-d0c4-2f242819ccac"
   },
   "outputs": [],
   "source": [
    "print('Using:')\n",
    "print('\\t\\u2022 TensorFlow version:', tf.__version__)\n",
    "print('\\t\\u2022 tf.keras version:', tf.keras.__version__)\n",
    "print('\\t\\u2022 Running on GPU' if tf.test.is_gpu_available() else '\\t\\u2022 GPU device not found. Running on CPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vr2SOjl8txrZ"
   },
   "source": [
    "## Load the Dataset\n",
    "\n",
    "이전에 했던 것처럼 `tensorflow_datasets`을 사용해서 Fashion-MNIST dataset을 load할 예정이다. 하지만 이 경우 `split` argument를 생략할 것이다. 이 말은 `tensorflow_datasets`가 `split`를 위해서 기본값인 `split=None`를 사용할 것이다. `split=None`일 때, `tensorflow_datasets`은 로딩하는 dataset에 대해서 유효한 모든 splits를 가지는 **dictionary**를 반환한다. 하지만 split이 명시적으로 `split='train'`와 같이 주어진 경우라면 `tensorflow_datasets`은 `tf.data.Dataset` object를 반환한다.\n",
    "\n",
    "이 경우 `fashion_mnist` dataset를 load할 것이다. 만약 [documentation](https://www.tensorflow.org/datasets/catalog/fashion_mnist#statistics)를 보면 이 특수한 dataset은 2개 splits를 가지는 것을 보게 되며 이름은 `train`와 `test`이다. `train` split은 60,000 예제를 가지고 있고 `test` split은 10,000 예제를 가지고 있다.\n",
    "\n",
    "이제 `fashion_mnist` dataset를 load하고 반환 값을 조사하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "1kn4Op7dXCnk",
    "outputId": "cd83ee11-b25e-4df2-dbf7-2026fd2049da"
   },
   "outputs": [],
   "source": [
    "dataset, dataset_info = tfds.load('fashion_mnist', as_supervised = True, with_info = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "2_vT6HUUXg05",
    "outputId": "fcdf4d7e-d14b-491b-b6c1-235823d67875"
   },
   "outputs": [],
   "source": [
    "# Check that dataset is a dictionary\n",
    "print('dataset has type:', type(dataset))\n",
    "\n",
    "# Print the keys of the dataset dictionary\n",
    "print('\\nThe keys of dataset are:', list(dataset.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6S4f2J9jbpak"
   },
   "source": [
    "아래 cell에서 training data를 저장하고 test data를 다른 변수에 저장한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kxo7PHJys18t"
   },
   "outputs": [],
   "source": [
    "training_set, test_set = dataset['train'], dataset['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zzZciG_KcHbI"
   },
   "source": [
    "이제 `dataset_info`를 살펴보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 598
    },
    "colab_type": "code",
    "id": "7jFE3vbebU-A",
    "outputId": "faaf389e-4d0b-4d51-f565-34aba4ae5cfd"
   },
   "outputs": [],
   "source": [
    "# Display the dataset_info\n",
    "dataset_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0_If36cti685"
   },
   "source": [
    "매우 쉽게 `dataset_info` 정보에 접근할 수 있다. 보는 바와 같이 `features` 와 `splits` info는 dictionaries에 포함된다. 이 dictionaries에 특정 key와 value에 접근해서 원하는 정보에 접근할 수 있다. 이 dictionaries에 있는 특정 key의 값을 살펴보자.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6KtD7j5HgTkn",
    "outputId": "926d32e3-644b-45ff-c86e-119663fcabc6"
   },
   "outputs": [],
   "source": [
    "dataset_info.features['image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "l_QXhcTOiQ1a",
    "outputId": "53da5e37-9e6e-45ee-c395-81166c3e6e5c"
   },
   "outputs": [],
   "source": [
    "dataset_info.features['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "gGn6yzTxgKwj",
    "outputId": "442c79f6-a5c6-4d4c-8b84-7f2d93778d81"
   },
   "outputs": [],
   "source": [
    "dataset_info.splits['train']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MFwhpPOijumG"
   },
   "source": [
    "원하는 정보에 접근하기 위해서 dot 표기법을 사용할 수 있다. 아래 몇가지 예제가 있다. :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "m9_OYPHsbbcl",
    "outputId": "9b7e79ce-1932-443c-85b9-1dca8b55eade"
   },
   "outputs": [],
   "source": [
    "shape_images = dataset_info.features['image'].shape\n",
    "num_classes = dataset_info.features['label'].num_classes\n",
    "\n",
    "num_training_examples  = dataset_info.splits['train'].num_examples\n",
    "num_test_examples = dataset_info.splits['test'].num_examples\n",
    "\n",
    "print('There are {:,} classes in our dataset'.format(num_classes))\n",
    "print('The images in our dataset have shape:', shape_images)\n",
    "\n",
    "print('\\nThere are {:,} images in the test set'.format(num_test_examples))\n",
    "print('There are {:,} images in the training set'.format(num_training_examples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nfMgIb3PvWXo"
   },
   "source": [
    "## Explore the Dataset\n",
    "\n",
    "이 dataset내에 images은 28 $\\times$ 28 arrays이고 `[0, 255]` 범위의 pixel 값을 가진다. *labels*은 정수의 array이고 `[0, 9]` 범위에 있다. 이는 image가 나타내는 clothing의 *class*와 일치하다.:\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <th>Label</th>\n",
    "    <th>Class</th> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>0</td>\n",
    "    <td>T-shirt/top</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>1</td>\n",
    "    <td>Trouser</td> \n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>2</td>\n",
    "    <td>Pullover</td> \n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>3</td>\n",
    "    <td>Dress</td> \n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>4</td>\n",
    "    <td>Coat</td> \n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>5</td>\n",
    "    <td>Sandal</td> \n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>6</td>\n",
    "    <td>Shirt</td> \n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>7</td>\n",
    "    <td>Sneaker</td> \n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>8</td>\n",
    "    <td>Bag</td> \n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>9</td>\n",
    "    <td>Ankle boot</td> \n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "각 image는 single label에 매핑된다. *class names*은 dataset에 포함되지 않기 때문에 image를 그릴때 사용해서 생성한다.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "odzN3aJjusED"
   },
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n",
    "               'Sandal',      'Shirt',   'Sneaker',  'Bag',   'Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "RoY1HeJJyces",
    "outputId": "c6d817e3-4150-4f8f-8b28-298b0936e794"
   },
   "outputs": [],
   "source": [
    "for image, label in training_set.take(1):\n",
    "    print('The images in the training set have:\\n\\u2022 dtype:', image.dtype, '\\n\\u2022 shape:', image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "colab_type": "code",
    "id": "CInprnnJ1_gk",
    "outputId": "aa2945e1-9f33-4d2e-8191-a47dd7dbb29f"
   },
   "outputs": [],
   "source": [
    "for image, label in training_set.take(1):\n",
    "    image = image.numpy().squeeze()\n",
    "    label = label.numpy()\n",
    "\n",
    "plt.imshow(image, cmap= plt.cm.binary)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "print('The label of this image is:', label)\n",
    "print('The class name of this image is:', class_names[label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hb-lmuTM35C9"
   },
   "source": [
    "## Create Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3gq-_mXl3ZFG"
   },
   "outputs": [],
   "source": [
    "def normalize(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image /= 255\n",
    "    return image, label\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "training_batches = training_set.cache().shuffle(num_training_examples//4).batch(batch_size).map(normalize).prefetch(1)\n",
    "testing_batches = test_set.cache().batch(batch_size).map(normalize).prefetch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LviX4-ii8js7"
   },
   "source": [
    "## Build the Model\n",
    "\n",
    "> **연습문제:** 여기서 여러분의 neural network을 정의해야한다. 자유롭게 원하는 만큼의 layer와 neurons를 사용해서 model을 생성하자. MNIST로 각 image는 28 $\\times$ 28 이고 전체 784 pixel이 되고 10개 classes가 있다. model에는 적어도 한개 이상의 hidden layer를 포함해야만 한다. hidden layers를 위한 ReLU activation과 output layer를 위한 softmax activation function 사용하도록 하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OYzFZ3jQ8azd"
   },
   "outputs": [],
   "source": [
    "## Solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CYhwsFzA-Aah"
   },
   "source": [
    "## Train the Model\n",
    "\n",
    "> **Exercise:** Compile the model you created above using an `adam` optimizer, a `sparse_categorical_crossentropy` loss function, and the `accuracy` metric. Then train the model for 5 epochs. You should be able to get the training loss below 0.4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "Cyy9SqTU91IS",
    "outputId": "e8823c12-e7c0-4397-8126-2cb29e8be66a"
   },
   "outputs": [],
   "source": [
    "## Solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "REJbwplUBoRT"
   },
   "source": [
    "## Evaluate Loss and Accuracy on the Test Set\n",
    "\n",
    "Now let's see how the model performs on the test set. This time, we will use all the examples in our test set to assess the loss and accuracy of our model. Remember, the images in the test are images the model has never seen before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "q76aDGGl_xp4",
    "outputId": "d1ee69fc-874c-4985-cbd3-5bae323f64fb"
   },
   "outputs": [],
   "source": [
    "loss, accuracy = my_model.evaluate(testing_batches)\n",
    "\n",
    "print('\\nLoss on the TEST Set: {:,.3f}'.format(loss))\n",
    "print('Accuracy on the TEST Set: {:.3%}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PnpZWDQp2Zaq"
   },
   "source": [
    "## Check Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "colab_type": "code",
    "id": "kqUzc4pYAe7Z",
    "outputId": "faa09287-401f-478d-85c1-6eb59eb748cd"
   },
   "outputs": [],
   "source": [
    "for image_batch, label_batch in testing_batches.take(1):\n",
    "    ps = my_model.predict(image_batch)\n",
    "    first_image = image_batch.numpy().squeeze()[0]\n",
    "    first_label = label_batch.numpy()[0]\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n",
    "ax1.imshow(first_image, cmap = plt.cm.binary)\n",
    "ax1.axis('off')\n",
    "ax1.set_title(class_names[first_label])\n",
    "ax2.barh(np.arange(10), ps[0])\n",
    "ax2.set_aspect(0.1)\n",
    "ax2.set_yticks(np.arange(10))\n",
    "ax2.set_yticklabels(class_names, size='small');\n",
    "ax2.set_title('Class Probability')\n",
    "ax2.set_xlim(0, 1.1)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gs6wGo79So1E"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Part 4 - Fashion-MNIST (Solution).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
