{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q9aaxiSJg60h"
   },
   "source": [
    "# Neural Networks 소개(with TensorFlow)\n",
    "\n",
    "이 notebook에서 [TensorFlow](https://www.tensorflow.org/)에 대해서 소개합니다. TensorFlow는 머신러닝 모델을 개발하고 train시키는 것을 돕는 오픈소스 라이브러리입니다.\n",
    "\n",
    "TensorFlow는 다양하게 NumPy에 있는 array와 비슷하게 동작한다. 결국 NumPy arrays는 tensors가 되는 것이다.\n",
    "TensorFlow는 이 tensors들을 받아서 GPUs에 이동시켜서 neural networks를 training시켜 더 빠르게 처리한다. TensorFlow는 gradients를 자동으로 계산할 수도 있으며 이는 backpropagation에 완벽하게 사용할 수 있고 특히 neural networks를 만들기 위해서 직관적인 high-level API를 가진다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q6WXEV-OiFY7"
   },
   "source": [
    "## Neural Networks\n",
    "\n",
    "Deep Learning은 1950년대 후반에 나온 artificial neural networks를 기반으로 한다. networks은 neurons를 흉내낸 개별 파츠로 구성된다. 일반적으로 units 혹은 간단히 \"neurons\"라고 부른다. 각 unit은 여러개의 weighted inputs를 가진다. 이런 weighted inputs은 같이 합쳐지고(linear combination) 나서 activation function로 전달되어 unit의 output을 얻는다.\n",
    "\n",
    "<img src=\"assets/simple_neuron.png\" width=400px>\n",
    "\n",
    "수학적으로 위 내용은 다음과 같다:\n",
    "\n",
    "$$\n",
    "y = f(h)\n",
    "$$\n",
    "\n",
    "where,\n",
    "\n",
    "$$\n",
    "h = w_1 x_1 + w_2 x_2 + b = \\sum_{i=1}^2 w_i x_i + b\n",
    "$$\n",
    "\n",
    "If we let $b = w_0x_0$, then we can express $h$ as the dot/inner product of two vectors:\n",
    "\n",
    "$$\n",
    "h = \\begin{bmatrix}\n",
    "x_0 \\, x_1 \\, x_2\n",
    "\\end{bmatrix}\n",
    "\\cdot \n",
    "\\begin{bmatrix}\n",
    "           w_0 \\\\\n",
    "           w_1 \\\\\n",
    "           w_2\n",
    "\\end{bmatrix} = w_0 x_0 + w_1 x_1 + w_2 x_2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AcBD-UAaiaUc"
   },
   "source": [
    "## Tensors\n",
    "\n",
    "neural network 계산은 *tensors*에 대한 선형대수 연산 다발 즉 매트릭스 연산이라 할 수 있다. vector는 1차원 tensor고 matrix는 2차원 tensor, 3개 index를 가지는 배열은 3차원 tensor(예로 RGB Color)이다. njeural network에 대한 기본 자료구조는 tensor고 TensorFlow는 tensors를 기반으로 만들어졌다.\n",
    "\n",
    "<img src=\"assets/tensor_examples.svg\" width=600px>\n",
    "\n",
    "기본을 익히기 위해서 TensorFlow를 사용하여 간단한 neural network를 만드는 방법을 경험해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pt6qo5hiesm7"
   },
   "source": [
    "## Import Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "adTiqrSxkPvL"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = tf.get_logger()\n",
    "logger.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "jyZjjOb-V4eo",
    "outputId": "0bb960f6-e973-46af-eccb-a923475310e3"
   },
   "outputs": [],
   "source": [
    "print('Using:')\n",
    "print('\\t\\u2022 TensorFlow version:', tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IVTYgypBfx2a"
   },
   "source": [
    "## Single Layer Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "UDJArguZkLPJ",
    "outputId": "8f187357-5089-49ab-8112-2819fa3ec786"
   },
   "outputs": [],
   "source": [
    "# random seed를 설정 (Set the random seed so things are reproducible)\n",
    "tf.random.set_seed(7) \n",
    "\n",
    "# 5개 random 입력 feature 생성 (Create 5 random input features)\n",
    "features = tf.random.normal((1, 5))\n",
    "\n",
    "# 5개 random weights를 생성 (Create random weights for our neural network)\n",
    "weights = tf.random.normal((1, 5))\n",
    "\n",
    "# neural network를 위해서 random bias term을 생성 (Create a random bias term for our neural network)\n",
    "bias = tf.random.normal((1, 1))\n",
    "\n",
    "print('Features:\\n', features)\n",
    "print('\\nWeights:\\n', weights)\n",
    "print('\\nBias:\\n', bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7o-2IomPkZx6"
   },
   "source": [
    "위에서 생성한 데이터는 간단한 network의 output을 얻는데 사용할 수 있다. 지금까지는 모두 random 이였고 앞으로는 실제 data를 사용해 보도록 하자.\n",
    "\n",
    "위에서 봤던 것처럼 TensorFlow에서 tensors는 `tf.Tensor` 객체로 data type과 shape을 가지고 있다. 이제 관련된 코드 라인을 살펴보자. :\n",
    "\n",
    "* `features = tf.random.normal((1, 5))` 는 `(1, 5)` shape을 가지는 tensor를 생성하며 1행 5열로 평균 0, 표준편차 1의 정규분포의 random 값들을 포함한다.\n",
    "\n",
    "* `weights = tf.random.normal((1, 5))` 는 `(1, 5)` shape을 가지는 tensor를 생성하며 1행 5열로 평균 0, 표준편차 1의 정규분포의 random 값들을 다시 포함한다.\n",
    "\n",
    "* `bias = tf.random.normal((1, 1))` 는 정규분포로 단일 random 값을 생성한다.\n",
    "\n",
    "TensorFlow의 tensors는 더하기, 곱하기, 빼기 등이 NumPy arrays처럼 가능하다. 일반적으로 NumPy arrays가 사용하는 것과 아주 유사한 방식으로 TensorFlow의 tensors를 사용한다. GPU 가속과 같은 장점을 사용할 수 있으면 나중에 설명한다. 이제 간단한 single layer network의 output를 계산하기 위해서 생성한 random data를 사용한다.\n",
    "\n",
    "이제 사용할 activation function을 생성하자 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wmOi7zjFgsMM"
   },
   "outputs": [],
   "source": [
    "def sigmoid_activation(x):\n",
    "    \"\"\" S자 activation function(Sigmoid activation function)\n",
    "    \n",
    "        인자 (Arguments)\n",
    "        ---------\n",
    "        x: tf.Tensor. Must be one of the following types: bfloat16, half, float32, float64, complex64, complex128.\n",
    "    \"\"\"\n",
    "    return 1/(1+tf.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "57QrwP-0gny1"
   },
   "source": [
    "이제 single layer neural network의 output을 계산해보자.\n",
    "\n",
    "> **연습문제**: network의 output을 계산하자. 이 network은 `features`, `weights`, `bias`를 가진다. NumPy와 유사하게 TensorFlow는 `tf.multiply(a, b)`로 `a` 와 `b` 엘리먼트를 곱한다. `tf.reduce_sum(x)`는 tensor `x`의 엘리먼트의 sum을 계산한다. 위에서 정의한 `sigmoid_activation` function을 activation function으로 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "qujbYK1nkaW-",
    "outputId": "d69a6561-5414-49e3-e8f3-419892991533"
   },
   "outputs": [],
   "source": [
    "## Solution\n",
    "y = \n",
    "\n",
    "print('label:\\n', y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gx6LpDRakgOD"
   },
   "source": [
    "행렬 곱셉을 사용하여 동일한 연산에서 곱셈과 합을 계산할 수 있다. 일반적으로 행렬 곱셈을 사용하려고 하는데 왜냐하면 최신 라이브러리를 사용하면 효율적이고 GPU의 고성능 가속을 사용할 수 있기 때문이다.\n",
    "\n",
    "여기서는 features와 weights의 행렬 곱셈을 하려고 한다. 이를 위해 `tf.matmul()` 를 사용할 수 있다. 만약에 `features` 와 `weights` 로 계산하면 error를 나타난다.\n",
    "\n",
    "```python\n",
    ">> tf.matmul(features, weights)\n",
    "\n",
    "---------------------------------------------------------------------------\n",
    "InvalidArgumentError                      Traceback (most recent call last)\n",
    "<ipython-input-7-66a4fe44f20b> in <module>()\n",
    "      1 \n",
    "----> 2 y = sigmoid_activation(tf.matmul(features, weights) + bias)\n",
    "\n",
    "2 frames\n",
    "/usr/local/lib/python3.6/dist-packages/six.py in raise_from(value, from_value)\n",
    "\n",
    "InvalidArgumentError: Matrix size-incompatible: In[0]: [1,5], In[1]: [1,5] [Op:MatMul] name: MatMul/\n",
    "```\n",
    "\n",
    "어떤 framework에서 neural networks를 만들때, 이런 경우를 진짜 자주 보게 된다. tensors가 행렬 곱셈에 알맞는 shape이 아니기 때문이다. 행렬 연산에서 첫번째 tensor에서 컬럼의 수는 반드시 2번째 tensor에 있는 행의 수와 같아야만 한다. `features` 와 `weights` 모두 `(1, 5)` 와 같이 동일한 shape을 가진다. 이 말은 행렬 곱셈이 동작하도록 `weights` shape을 변경해야한다.\n",
    "\n",
    "**Note:** `tensor` 라는 tensor의 shape을 보기 위해서 `tensor.shape` 을 사용한다. 만약 neural networks을 만들려면 이런 방법을 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "5flC0NB5uSlk",
    "outputId": "2aa713f0-3563-4845-bdd9-5331e07e694d"
   },
   "outputs": [],
   "source": [
    "print('Features Shape:', features.shape)\n",
    "print('Weights Shape:', weights.shape)\n",
    "print('Bias Shape:', bias.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lC0vZqQWvBon"
   },
   "source": [
    "이제 행렬 곱셈이 동작하도록 `weights` tensor 의 shape을 변경이 필요하다. 하지만 `tf.matmul(a,b)` function을 사용하면 이런 작업이 필요없다. `tf.matmul(a,b)` function는 인자로 `transpose_a` 와 `transpose_b` 를 가지며 `a` 나 `b` tensors를 곱셈을 위한 변환을 허용하여 tensor의 shape을 변경하지 않아도 된다. 따라서 이 경우 `transpose_b = True` 인자를 사용하여 `weights` tensor 를 `(1,5)` 에서 `(5,1)` 로 변환하여 곱셈을 할 수 있다.\n",
    "\n",
    "> **연습문제**: 행렬 곱셈을 사용하는 network의 output을 계산한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "iIQOahT4kg4H",
    "outputId": "273d8dcb-ade7-46ad-f720-6c439e837d4d"
   },
   "outputs": [],
   "source": [
    "## Solution\n",
    "y = \n",
    "\n",
    "print('label:\\n', y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pxzezexmkpzs"
   },
   "source": [
    "전과 같은 값이 나오는 것을 볼 수 있다. 이제 `weights` tensor 의 shape이 `transpose_b = True` 인자로 변경되지 않았는지 확인해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "XoESCJcLkrI5",
    "outputId": "d771c85d-ba0b-4a17-cff1-812edf3aa61b"
   },
   "outputs": [],
   "source": [
    "print('Weights Shape:', weights.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hYAyS685kv4e"
   },
   "source": [
    "보는 바와 같이 `weights` tensor의 shape는 변경되지 않은 상태로 남아있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ktu4Jfq3kzWx"
   },
   "source": [
    "## Multi-Layer Neural Network\n",
    "\n",
    "single neuron에 대한 output을 계산하는 방법이다. 이 알고리즘의 실제 파워는 이런 개별 units들을 layers로 쌓고 layers의 stacks을 neurons의 network이 될 때이다. 1개 layer 뉴런의 output은 다음 layer의 input이 된다. 여러 input units과 output units으로 이제 weights를 matrix로 표현하면 된다.\n",
    "\n",
    "<img src='assets/multilayer_diagram_weights.png' width=450px>\n",
    "\n",
    "위 다이어그램에서 바닥에 나타난 첫번째 layer는 inputs이고, 이해를 돕기 위해서 **input layer**라고 부르자. 중간 layer를 **hidden layer**로 마지막 layer(상단)는 **output layer**이 된다. 이런 network를 수학적으로 행렬로 표현할 수 있고 행렬 곱셈을 이용하면 각 unit을 위한 선형 조합을 얻을 수 있다. 예로 hidden layer($h_1$ 와 $h_2$ 로 구성)는 다음과 같이 계산한다 :\n",
    "\n",
    "$$\n",
    "\\vec{h} = [h_1 \\, h_2] = \n",
    "\\begin{bmatrix}\n",
    "x_1 \\, x_2 \\cdots \\, x_n\n",
    "\\end{bmatrix}\n",
    "\\cdot \n",
    "\\begin{bmatrix}\n",
    "           w_{11} & w_{12} \\\\\n",
    "           w_{21} &w_{22} \\\\\n",
    "           \\vdots &\\vdots \\\\\n",
    "           w_{n1} &w_{n2}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "이 작은 network에 대한 output은 output unit을 위한 hidden layer를 입력으로 취급하는 것으로 볼 수 있다. network output은 단순히 다음과 같이 표현한다 :\n",
    "\n",
    "$$\n",
    "y =  f_2 \\! \\left(\\, f_1 \\! \\left(\\vec{x} \\, \\mathbf{W_1}\\right) \\mathbf{W_2} \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yWRfPCIKkwZb"
   },
   "outputs": [],
   "source": [
    "# random seed를 설정 (Set the random seed so things are reproducible)\n",
    "tf.random.set_seed(7) \n",
    "\n",
    "# 3개 random input features를 생성 (Create 3 random input features)\n",
    "features = tf.random.normal((1,3))\n",
    "\n",
    "# network 내부에서 각 layer의 size를 정의 (Define the size of each layer in our network)\n",
    "n_input = features.shape[1]     # input units의 개수(input features의 개수와 같아야함) Number of input units, must match number of input features\n",
    "n_hidden = 2                    # hidden units의 개수 (Number of hidden units)\n",
    "n_output = 1                    # output units의 개수 (Number of output units)\n",
    "\n",
    "# input을 hidden layer에 연결한 random weights 생성 (Create random weights connecting the inputs to the hidden layer)\n",
    "W1 = tf.random.normal((n_input,n_hidden))\n",
    "\n",
    "# hidden layer를 output layer에 연결하는 random weights 생성 (Create random weights connecting the hidden layer to the output layer)\n",
    "W2 = tf.random.normal((n_hidden, n_output))\n",
    "\n",
    "# hidden과 output layers를 위한 random bias terms 생성 (Create random bias terms for the hidden and output layers)\n",
    "B1 = tf.random.normal((1,n_hidden))\n",
    "B2 = tf.random.normal((1, n_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cCRRqGFik5N8"
   },
   "source": [
    "> **연습문제:** weights `W1` & `W2`, 와 biases, `B1` & `B2` 를 사용해서 multi-layer network를 위한 output을 계산하라."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "eKKfk_jyk5_n",
    "outputId": "fc2f418d-21f7-458f-8905-36dd9bdc183e"
   },
   "outputs": [],
   "source": [
    "## Solution\n",
    "\n",
    "output = \n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Q1QzBpFlAFj"
   },
   "source": [
    "만약 제대로 수행되었다면 다음과 같은 output을 나와야 한다 : `tf.Tensor([[0.10678572]], shape=(1, 1), dtype=float32)`\n",
    "\n",
    "hidden units의 개수는 network의 parameter이며 이를 weights와 biases parameters와 구별하기 위해서 **hyperparameter** 라고 부른다. neural network를 training시키는 것에 대해서 나중에 볼 것이고 어떤 network가 더 많은 hidden layers와 units를 가질 수록 data로부터 더 잘 학습할 수 있고 더 정확한 predictions이 될 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qASlsncVlDRi"
   },
   "source": [
    "## NumPy to TensorFlow and Back\n",
    "\n",
    "여기는 특별 보너스 섹션이다. TensorFlow는 NumPy의 `ndarrays` 와 `tf.Tensors` 사이에 변환을 위해서 feature를 가진다. NumPy ndarray로부터 tensor를 생성하기 위해서 `tf.convert_to_tensor()` 를 사용한다. tensor를 NumPy array로 변환하기 위해서 `.numpy()` method를 사용한다. 아래는 관련된 예제이다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "5MHSE0uqlAsS",
    "outputId": "22d3e319-e6c3-4bce-8f92-5414558df10c"
   },
   "outputs": [],
   "source": [
    "# random seed를 설정 (Set the random seed so things are reproducible)\n",
    "tf.random.set_seed(7) \n",
    "\n",
    "a = np.random.rand(4,3)\n",
    "\n",
    "print(type(a))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "VceuFk3GlKKL",
    "outputId": "8691f3b8-8b74-403c-cf5a-f7274aef0c9c"
   },
   "outputs": [],
   "source": [
    "b = tf.convert_to_tensor(a)\n",
    "\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "QOh6E9SBlMzj",
    "outputId": "40de0a13-be50-4c94-cd9b-fc20e1396646"
   },
   "outputs": [],
   "source": [
    "c = b.numpy()\n",
    "\n",
    "print(type(c))\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ua9iXmXBlP4M"
   },
   "source": [
    "Tensor의 값을 변경한다면 ndarray의 값은 변경되지 않고, 반대로도 마찬가지다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "BC_O_BcOlTHa",
    "outputId": "c49af615-b311-4c6c-c66d-636f32dd654b"
   },
   "outputs": [],
   "source": [
    "# TensorFlow Tensor에 40 곱하기 (Multiply TensorFlow Tensor by 40)\n",
    "b = b * 40\n",
    "\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "R1gxSglFlV2R",
    "outputId": "3944e74f-62c4-4222-d505-b647ea24f4e1"
   },
   "outputs": [],
   "source": [
    "# NumPy array는 동일하게 유지 (NumPy array stays the same)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "4tkHnTSbNKdE",
    "outputId": "85afcc3d-cfdd-4db0-e246-3e05ff76a04e"
   },
   "outputs": [],
   "source": [
    "# NumPy array는 동일하게 유지 (NumPy array stays the same)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "z_vdtpxnlYUN",
    "outputId": "2788ac27-bb7f-4738-9d23-c96d09f0326a"
   },
   "outputs": [],
   "source": [
    "# NumPy ndarray에 1을 더하기 (Add 1 to NumPy ndarray)\n",
    "a = a + 1\n",
    "\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "sdtiRFFDlblU",
    "outputId": "67e8adc1-55e0-498a-de20-f4f2512ce961"
   },
   "outputs": [],
   "source": [
    "# Tensor는 동일하게 유지 (Tensor stays the same)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NumPy array는 동일하게 유지 (NumPy array stays the same)\n",
    "c"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Part 1 - Introduction to Neural Networks with TensorFlow (Solution).ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
